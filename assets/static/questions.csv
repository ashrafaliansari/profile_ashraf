Question,Option1,Option2,Option3,Option4,CorrectOption
What is Apache Spark used for?,Big data processing,Web scraping,Cloud computing,Data storage,Big data processing
Which of the following languages can be used to write Spark programs?,Java,Python,Scala,All of the above,All of the above
What is the main abstraction in Spark for working with data?,DataFrame,Dataset,Resilient Distributed Dataset (RDD),SparkSession,Resilient Distributed Dataset (RDD)
Which operation in Spark is used to perform transformations on RDDs?,map(),collect(),reduce(),show(),map()
What does `SparkContext` do in Apache Spark?,It is the entry point for Spark functionality,It is used to define SQL operations,It is used to store RDDs,It is used to create DataFrames,It is the entry point for Spark functionality
Which of the following is true about Spark's fault tolerance mechanism?,RDDs are immutable and can be recomputed in case of failure,RDDs are mutable and can be recomputed in case of failure,DataFrames are immutable but not fault-tolerant,DataFrames can be recomputed in case of failure,RDDs are immutable and can be recomputed in case of failure
What is a Spark cluster manager?,A tool used for managing Spark jobs across clusters,A tool used for managing data storage,A tool used for processing large datasets,A tool used for optimizing Spark queries,A tool used for managing Spark jobs across clusters
What does the `reduce()` operation do in Spark?,It aggregates the values of an RDD using a binary operator,It filters the elements of an RDD,It performs a transformation on an RDD,It collects the elements of an RDD,It aggregates the values of an RDD using a binary operator
What is the purpose of the `SparkSession` in Apache Spark?,It is the entry point for Spark SQL,It is used to perform RDD transformations,It is used to read and write data in HDFS,It is used to manage Spark clusters,It is the entry point for Spark SQL
Which of the following is NOT a valid source for reading data in Spark?,HDFS,Apache Kafka,MySQL,Excel,Excel